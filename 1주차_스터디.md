### 목차
* [하둡이란](#하둡이란)
* [데이터 분석 아키텍쳐](#데이터-분석-아키텍쳐)
* [실습](#실)
    - [Virtual Box 다운로드](#Virtual-box-다운로드)
    - [CentOS 7 다운로드](#centos-7-다운로드)
    - [가상머신 콘솔에서 고정 IP 설정](#가상머신-콘솔에서-고정-IP-설정)
    - [가상머신에 ssh 접속](#가상머신에-ssh-접속)
    - [필요한 리눅스 프로그램 설치](#필요한-리눅스-프로그램-설치)
    - [JAVA 다운로드 및 설치](#JAVA-다운로드-및-설치)
    - [가상 머신 중단 및 VDI 이미지 백업하기](#가상-머신-중단-및-VDI-이미지-백업하기)
    - [VDI 파일 백업하기](#VDI-파일-백업하기)
- [하둡 기본 명령어 실습](#하둡-기본-명령어)
- [샘플 데이터](#샘플-데이터)

## 하둡이란
대용량 데이터 저장소

## 데이터 분석 아키텍쳐
- 수집 -> 적재 -> 처리/탐색 -> 분석/응용

#### 이번 실습에서의 필요 사양 (학습/테스트 용도)
- CPU : 듀얼코어 2.93Gz
- 램 : 2.0GB
- 하드디스크 : 100GB
- OS : CentOS 6 이상


#### [참고] 빅데이터 파일럿 프로젝트 시, 필요 사양
- 다양한 하둡 에코 시스템을 사용하는 파일럿 프로젝트를 사용할 때의 사양
- 메모리에 대한 리소스 사용률이 높으므로 여유 메모리를 최대한 확보

리소스 구분  | 저사양 파일럿 환경 | 고사양환경 | 비고
--------- | -------------- | ------- | ----
CPU | 듀얼코어 이상 | i5 이상 | i3 이상 권장
메모리| 8GB 이상 (여유 7GB) | 16GB 이상(여유 15GB) | 16GB 이상 권장
디스크 | 60GB 이상 | 100GB 이상 | SSD 권장


- OS는 CentOS 권장 (오픈소스 표준)

#### Virtual Box
- 가상머신이란?
- 가상머신을 왜 사용하는가?
- 대표적인 가상머신으로는 **Virtual Box**와 **VMWare**가 있다

## 실습
### 다운로드
#### Oracle Virtual Box 다운로드
- https://www.virtualbox.org/wiki/Downloads

#### CentOS 7 iso 다운로드
- http://mirror.retentionrange.co.bw/centOS/7/isos/x86_64/

#### putty 다운로드
- https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html

### Virtual Box 이미지 올리고 환경 설정
- PPT 참고

### Virtual Box 가상 머신 콘솔 실행
#### 인터넷 연결 확인
~~~
$ ping -c 2 www.google.com
~~~
#### 가상머신 콘솔에서 고정 IP 설정
- 가상머신 콘솔에서 root로 로그인

~~~
client login: root
Password:  [hadoop]입력해주세요
~~~

- ifconfig 설치

~~~
[1]$ yum  install  -y  net-tools
~~~
~~~
[root@client ~]# yum install -y net-tools
Loaded plugins: fastestmirror
...
Dependencies Resolved
================================================================================
 Package         Arch         Version                          Repository  Size
================================================================================
Installing:
 net-tools       x86_64       2.0-0.17.20131004git.el7         base       304 k

Transaction Summary
================================================================================
...
Running transaction
  Installing : net-tools-2.0-0.17.20131004git.el7.x86_64                    1/1
  Verifying  : net-tools-2.0-0.17.20131004git.el7.x86_64                    1/1

Installed:
  net-tools.x86_64 0:2.0-0.17.20131004git.el7

Complete!
-----------------------------------------------------------------------------------
~~~
-  먼저 IP 설정을 확인하고 디바이스 이름( enp... 로 시작) 확인

~~~
[2]$ ip a
~~~
~~~
[root@client ~]# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: enp0s3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP qlen 1000
    link/ether 12:34:56:78:90:20 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic enp0s3
       valid_lft 73401sec preferred_lft 73401sec
    inet6 fe80::de96:c091:e0e0:a35f/64 scope link
       valid_lft forever preferred_lft forever
3: enp0s8: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP qlen 1000
    link/ether 12:34:56:78:90:21 brd ff:ff:ff:ff:ff:ff
    inet 192.168.56.101/24 brd 192.168.56.255 scope global dynamic enp0s8
       valid_lft 1099sec preferred_lft 1099sec
    inet6 fe80::58f4:a9a4:185b:2f73/64 scope link
       valid_lft forever preferred_lft forever
~~~

[ 3: enp0s8 ] 디바이스에 [ inet 192.168.56.101/24 ] 확인
                         (192.168.56.1XX)

IP를 고정시켜 줌
~~~
[3]$ ifconfig  enp0s8  192.168.56.21
[4]$ ip  a
~~~
부팅시 자동으로 실행되도록 rc.local에 추가

// 지금 실행하면 안됩니다. echo 'ifconfig  enp0s8  192.168.56.21' >> /etc/rc.d/rc.local

~~~
[root@client ~]# ifconfig  enp0s8  192.168.56.21

[root@client ~]# ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: enp0s3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP qlen 1000
    link/ether 12:34:56:78:90:20 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic enp0s3
       valid_lft 73183sec preferred_lft 73183sec
    inet6 fe80::de96:c091:e0e0:a35f/64 scope link
       valid_lft forever preferred_lft forever
3: enp0s8: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP qlen 1000
    link/ether 12:34:56:78:90:21 brd ff:ff:ff:ff:ff:ff
    inet 192.168.56.21/24 brd 192.168.56.255 scope global enp0s8
       valid_lft forever preferred_lft forever
    inet6 fe80::58f4:a9a4:185b:2f73/64 scope link
       valid_lft forever preferred_lft forever
~~~

출력 화면에서 다음과 같이 IP 설정된 것을 확인해야 함

~~~
1: log    => 127.0.0.1
2: enpXXX => 10.0.2.15
3: enpXXX => 192.168.56.21
~~~


#### 가상머신에 ssh 접속 (Putty)
~~~
IP : 192.168.56.21
~~~  
외부 네트워크 연결 확인하기
~~~
[1]$ hostname
[2]$ ping -c 2 www.google.com
~~~
~~~
//  네트워크 연결이 안될 경우!
[NOTE] 먼저 노트북/PC의 인터넷 연결 여부를 확인하세요.
[root@client ~]# echo 'nameserver 8.8.8.8' >> /etc/resolv.conf
// 실행 후, 다시 ping -c 2 www.google.com
~~~

~~~
login as: root
root@192.168.56.21's password:
Last login: Fri May 26 18:13:00 2017 from 192.168.56.1

[root@client ~]# hostname
client.hadoop.kr

[root@client ~]# ping -c 2 www.google.com
PING www.google.com (216.58.197.4) 56(84) bytes of data.
64 bytes from kix06s02-in-f4.1e100.net (216.58.197.4): icmp_seq=1 ttl=51 time=45.7 ms
64 bytes from kix06s02-in-f4.1e100.net (216.58.197.4): icmp_seq=2 ttl=51 time=39.5 ms

--- www.google.com ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1002ms
rtt min/avg/max/mdev = 39.538/42.639/45.740/3.101 ms
~~~
#### 필요한 리눅스 프로그램 설치
- ftp, wget 프로그램 설치
~~~
[3]$ yum install -y ftp wget
~~~
~~~
[root@client ~]# rpm -qa | grep wget
[root@client ~]# rpm -qa | grep ftp
[root@client ~]# yum install -y ftp wget
Loaded plugins: fastestmirror
...
  Installing : ftp-0.17-67.el7.x86_64                                                                   1/2
  Installing : wget-1.14-13.el7.x86_64                                                                  2/2
  Verifying  : wget-1.14-13.el7.x86_64                                                                  1/2
  Verifying  : ftp-0.17-67.el7.x86_64                                                                   2/2

Installed:
  ftp.x86_64 0:0.17-67.el7         wget.x86_64 0:1.14-13.el7

Complete!
~~~

Mysql 설치
- 마리아DB 대신 Mysql 설치할 수 있게 해주는 패키지 다운로드
~~~
[4]$ wget www.db21.co.kr/big/mysql-community-release-el7-5.noarch.rpm
~~~
패키지 설치
~~~
[5]$ yum -y install mysql-community-release-el7-5.noarch.rpm
~~~

Mysql 설치
~~~
[6]$ yum -y install mysql-community-server
~~~

Mysql 서버 시작
~~~
[7]$ systemctl start mysqld
~~~

(옵선) 리눅스 부팅시 Mysql 서버 자동 시작 설정(일단 하지 X)
~~~
[8]$ s y s t e m c t l enable mysql
~~~

설정 확인
~~~
[9]$ systemctl status mysqld
~~~
Mysql 서버 동작 확인
~~~
[10] $ mysqlshow
~~~

~~~
[root@client ~]# wget www.db21.co.kr/big/mysql-community-release-el7-5.noarch.rpm
--2017-05-26 18:51:17--  http://www.db21.co.kr/big/mysql-community-release-el7-5.noarch.rpm
Resolving www.db21.co.kr (www.db21.co.kr)... 121.124.124.244
Connecting to www.db21.co.kr (www.db21.co.kr)|121.124.124.244|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 6140 (6.0K) [text/plain]
Saving to: ‘mysql-community-release-el7-5.noarch.rpm’

100%[==================================================================>] 6,140       --.-K/s   in 0.004s

2017-05-26 18:51:17 (1.38 MB/s) - ‘mysql-community-release-el7-5.noarch.rpm’ saved [6140/6140]

[root@client ~]# yum -y install mysql-community-release-el7-5.noarch.rpm
Loaded plugins: fastestmirror
...
Running transaction
  Installing : mysql-community-release-el7-5.noarch                                                     1/1
  Verifying  : mysql-community-release-el7-5.noarch                                                     1/1

Installed:
  mysql-community-release.noarch 0:el7-5

Complete!

[root@client ~]# yum -y install mysql-community-server
Loaded plugins: fastestmirror

Installed:
  mysql-community-libs.x86_64 0:5.6.36-2.el7          mysql-community-server.x86_64 0:5.6.36-2.el7

Dependency Installed:
  libaio.x86_64 0:0.3.109-13.el7                       mysql-community-client.x86_64 0:5.6.36-2.el7
  mysql-community-common.x86_64 0:5.6.36-2.el7         perl.x86_64 4:5.16.3-291.el7
...
  perl-threads-shared.x86_64 0:1.43-6.el7

Replaced:
  mariadb-libs.x86_64 1:5.5.52-1.el7

Complete!
~~~

~~~
[root@client ~]# systemctl start mysqld

[root@client ~]# systemctl enable mysqld

[root@client ~]# systemctl status mysqld
● mysqld.service - MySQL Community Server
   Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled)
   Active: active (running) since 금 2017-05-26 18:54:20 KST; 11s ago
 Main PID: 8901 (mysqld_safe)
   CGroup: /system.slice/mysqld.service
           ├─8901 /bin/sh /usr/bin/mysqld_safe --basedir=/usr
           └─9068 /usr/sbin/mysqld --basedir=/usr --datadir=/var/lib/mysql --plugin-dir=/usr/lib64/mysql/...

 5월 26 18:54:19 client.hadoop.kr mysql-systemd-start[8842]: Support MySQL by buying support/licenses ...om
 ...
 5월 26 18:54:20 client.hadoop.kr systemd[1]: Started MySQL Community Server.
Hint: Some lines were ellipsized, use -l to show in full.

[root@client ~]# mysqlshow
+--------------------+
|     Databases      |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
+--------------------+
~~~

#### JAVA 다운로드 및 설치
- JAVA 다운로드(64비트)
~~~
[11]$ wget www.db21.co.kr/hadoop/jdk-7u55-linux-x64.rpm

[root@client ~]# wget www.db21.co.kr/hadoop/jdk-7u55-linux-x64.rpm
--2017-05-26 18:26:00--  http://www.db21.co.kr/hadoop/jdk-7u55-linux-x64.rpm
Resolving www.db21.co.kr (www.db21.co.kr)... 121.124.124.244
Connecting to www.db21.co.kr (www.db21.co.kr)|121.124.124.244|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 122656363 (117M) [text/plain]
Saving to: ‘jdk-7u55-linux-x64.rpm’

100%[===============================================>] 122,656,363 2.17MB/s   in 57s

2017-05-26 18:26:58 (2.04 MB/s) - ‘jdk-7u55-linux-x64.rpm’ saved [122656363/122656363]
~~~

**JAVA 설치**

[NOTE] 하둡계정은 별도의 JDK 버전을 사용함
- JDK의 설치 여부를 확인

~~~
[12]$ rpm -qa | grep 'jdk'
=> 아무것도 안나오면 정상!

[13]$ ls
=> JDK 설치

[14]$ rpm  -ivh  jdk-7u55-linux-x64.rpm
=> 심벌릭 링크를 걸어줌(버전 업그레이드할 때 편리함)

[15]$ ln  -s  /usr/java/jdk1.7.0_55  /usr/local/java

[16]$ ll /usr/local
~~~

~~~
[root@client ~]# rpm -qa | grep 'jdk'

[root@client ~]# ls
anaconda-ks.cfg  jdk-7u55-linux-x64.rpm  mysql-community-release-el7-5.noarch.rpm

[root@client ~]# rpm  -ivh  jdk-7u55-linux-x64.rpm
준비 중...                         ################################# [100%]
Updating / installing...
   1:jdk-2000:1.7.0_55-fcs            ################################# [100%]
Unpacking JAR files...
        rt.jar...
        jsse.jar...
        charsets.jar...
        tools.jar...
        localedata.jar...
        jfxrt.jar...

[root@client ~]# ln  -s  /usr/java/jdk1.7.0_55  /usr/local/java

[root@client ~]# ll /usr/local
합계 0
drwxr-xr-x. 2 root root  6 11월  6  2016 bin
drwxr-xr-x. 2 root root  6 11월  6  2016 etc
drwxr-xr-x. 2 root root  6 11월  6  2016 games
drwxr-xr-x. 2 root root  6 11월  6  2016 include
lrwxrwxrwx. 1 root root 21  5월 26 19:01 java -> /usr/java/jdk1.7.0_55
drwxr-xr-x. 2 root root  6 11월  6  2016 lib
drwxr-xr-x. 2 root root  6 11월  6  2016 lib64
drwxr-xr-x. 2 root root  6 11월  6  2016 libexec
drwxr-xr-x. 2 root root  6 11월  6  2016 sbin
drwxr-xr-x. 5 root root 49  5월 26 14:33 share
drwxr-xr-x. 2 root root  6 11월  6  2016 src
------------------------------------------------------------
~~~

**추가 작업 및 설정**

1.방화벽 중단하기
~~~
$ systemctl status firewalld

$ systemctl stop firewalld

$ systemctl disable firewalld
~~~
2.JDK RPM 파일 삭제
~~~
$ ll
$ rm jdk-7u55-linux-x64.rpm
~~~

**하둡 설치 관련 파일 다운로드**

- 리눅스 하둡 계정(hadoop) 추가
- 비밀번호는 hadoop
~~~
[1]$ adduser hadoop
[2]$ passwd hadoop
~~~

~~~
[root@client ~]# adduser hadoop
[root@client ~]# passwd hadoop
hadoop 사용자의 비밀 번호 변경 중
새  암호:
잘못된 암호: 암호는 8 개의 문자 보다 짧습니다
새  암호 재입력:
passwd: 모든 인증 토큰이 성공적으로 업데이트 되었습니다.
~~~

- 하둡 데이터 디렉터리 만들고 권한 부여

~~~
[3]$ mkdir   /data
[4]$ chown  hadoop  /data
[5]$ chgrp  hadoop  /data
[6]$ ll  /
~~~

~~~
[root@client ~]# mkdir  /data
[root@client ~]# chown  hadoop  /data
[root@client ~]# chgrp  Hadoop  /data
[root@client ~]# ll /
합계 16
lrwxrwxrwx.   1 root   root      7  5월 31 14:43 bin -> usr/bin
dr-xr-xr-x.   4 root   root   4096  5월 31 14:46 boot
drwxr-xr-x.   2 hadoop hadoop    6  5월 31 15:47 data
drwxr-xr-x.  17 root   root   2980  5월 31 14:50 dev
drwxr-xr-x.  76 root   root   8192  5월 31 15:47 etc
drwxr-xr-x.   3 root   root     20  5월 31 15:47 home
lrwxrwxrwx.   1 root   root      7  5월 31 14:43 lib -> usr/lib
lrwxrwxrwx.   1 root   root      9  5월 31 14:43 lib64 -> usr/lib64
drwxr-xr-x.   2 root   root      6 11월  6  2016 media
drwxr-xr-x.   2 root   root      6 11월  6  2016 mnt
drwxr-xr-x.   2 root   root      6 11월  6  2016 opt
dr-xr-xr-x. 103 root   root      0  5월 31 14:50 proc
dr-xr-x---.   2 root   root    192  5월 31 15:46 root
drwxr-xr-x.  22 root   root    640  5월 31 15:44 run
lrwxrwxrwx.   1 root   root      8  5월 31 14:43 sbin -> usr/sbin
drwxr-xr-x.   2 root   root      6 11월  6  2016 srv
dr-xr-xr-x.  13 root   root      0  5월 31 14:50 sys
drwxrwxrwt.   7 root   root    132  5월 31 15:46 tmp
drwxr-xr-x.  14 root   root    167  5월 31 15:47 usr
drwxr-xr-x.  19 root   root    267  5월 31 14:50 var
~~~

**SSH 처음 접속시 질문안받기**


~~~
[7]$ echo 'StrictHostKeyChecking no' >> /etc/ssh/ssh_config
~~~

[NOTE] 나중에 IP 설정이 꼬이면 아예 접속이 안됨
       이때는 ~/.ssh/known_hosts 삭제하면 됨!!!
       ( /root 또는 /home/hadoop )
~~~
[8]$ tail  /etc/ssh/ssh_config
~~~


~~~
[root@client ~]# echo 'StrictHostKeyChecking no' >> /etc/ssh/ssh_config

[root@client ~]# tail  /etc/ssh/ssh_config
# If this option is set to yes then remote X11 clients will have full access
# to the original X11 display. As virtually no X11 client supports the untrusted
# mode correctly we set this to yes.
        ForwardX11Trusted yes
# Send locale-related environment variables
        SendEnv LANG LC_CTYPE LC_NUMERIC LC_TIME LC_COLLATE LC_MONETARY LC_MESSAGES
        SendEnv LC_PAPER LC_NAME LC_ADDRESS LC_TELEPHONE LC_MEASUREMENT
        SendEnv LC_IDENTIFICATION LC_ALL LANGUAGE
        SendEnv XMODIFIERS
StrictHostKeyChecking no
[root@client ~]#
~~~

**하둡 계정으로 로그인하여 필요한 파일 다운로드**
~~~
[9]$ su  -  hadoop
~~~
[NOTE] 띄어쓰기 조심 : "su" 한칸 "-"(마이너스) 한칸 "hadoop"

=> Prompt가 다음과 같이 변경된 것을 확인하세요.
~~~
[root@client ~]# su  -  hadoop
[hadoop@client ~]$
~~~


=> 이제부터는 root가 아닌 hadoop 계정으로 작업합니다.
~~~
[1]$ whoami
     pwd
~~~
~~~
[hadoop@client ~]$ whoami
hadoop
[hadoop@client ~]$ pwd
/home/hadoop
~~~

**필요한 하둡 관련 파일 다운로드**
~~~
[2]$ wget www.db21.co.kr/big/hadoop-2.6.4.tar.gz
     wget www.db21.co.kr/big/bashrc2.txt
     wget www.db21.co.kr/big/pig-0.16.0.tar.gz
     wget www.db21.co.kr/big/apache-hive-1.2.1-bin.tar.gz
     wget www.db21.co.kr/big/hive-1.2.1-site.xml
     wget www.db21.co.kr/big/mysql-connector-java-5.1.23-bin.jar
     wget www.db21.co.kr/big/spark-1.6.2-bin-hadoop2.6.tgz
~~~
~~~
[hadoop@client ~]$ wget www.db21.co.kr/big/hadoop-2.6.4.tar.gz
--2017-05-26 18:32:05--  http://www.db21.co.kr/big/hadoop-2.6.4.tar.gz
Resolving www.db21.co.kr (www.db21.co.kr)...     

...
...

Saving to: ‘spark-1.6.2-bin-hadoop2.6.tgz’
100%[=====================================>] 278,057,117 4.51MB/s   in 71s
2017-05-26 18:35:13 (3.73 MB/s) - ‘spark-1.6.2-bin-hadoop2.6.tgz’ saved [278057117/278057117]
~~~

==> Hadoop, Pig, Hive, Spark 압축풀고 링크 걸기


##### 하둡 압축풀기

하둡 Tarball 파일 압축 풀기
~~~
[3]$ tar xvzf hadoop-2.6.4.tar.gz
~~~

버전 관리를 위해서 심벌릭 링크 걸기

~~~
[4]$ ln -s  /home/hadoop/hadoop-2.6.4  /home/hadoop/hadoop
~~~

##### Pig 압축풀기

Pig Tarball 파일 압축 풀기
~~~
[5]$ tar xvzf  pig-0.16.0.tar.gz
~~~

버전 관리를 위해서 심벌릭 링크 걸기
~~~
[6]$ ln -s  pig-0.16.0  pig
~~~

##### Hive 압축풀기

Hive Tarball 파일 압축 풀기
~~~
[7]$ tar xvzf apache-hive-1.2.1-bin.tar.gz
~~~
버전 관리를 위해서 심벌릭 링크 걸기
~~~
[8]$ ln -s apache-hive-1.2.1-bin  hive
~~~

##### Spark 압축풀기

- Spark Tarball 파일 압축 풀기
~~~
[9]$ tar xvzf  spark-1.6.2-bin-hadoop2.6.tgz
[10]$ ln -s  spark-1.6.2-bin-hadoop2.6  spark
~~~

##### 확인하기

~~~
[11]$ ll
~~~

~~~
[hadoop@client ~]$ ll
합계 727756
drwxrwxr-x.  8 hadoop hadoop       159  5월 26 19:07 apache-hive-1.2.1-bin
-rw-rw-r--.  1 hadoop hadoop  92834839  6월 27  2015 apache-hive-1.2.1-bin.tar.gz
-rw-rw-r--.  1 hadoop hadoop      1512  9월 17  2016 bashrc2.txt
lrwxrwxrwx.  1 hadoop hadoop        25  5월 26 19:07 hadoop -> /home/hadoop/hadoop-2.6.4
drwxr-xr-x.  9 hadoop hadoop       149  2월 12  2016 hadoop-2.6.4
-rw-rw-r--.  1 hadoop hadoop 196015975  2월 12  2016 hadoop-2.6.4.tar.gz
lrwxrwxrwx.  1 hadoop hadoop        21  5월 26 19:07 hive -> apache-hive-1.2.1-bin
-rw-rw-r--.  1 hadoop hadoop    168409  9월 17  2016 hive-1.2.1-site.xml
-rw-rw-r--.  1 hadoop hadoop    843090  3월 24  2013 mysql-connector-java-5.1.23-bin.jar
lrwxrwxrwx.  1 hadoop hadoop        10  5월 26 19:07 pig -> pig-0.16.0
drwxr-xr-x. 16 hadoop hadoop      4096  6월  2  2016 pig-0.16.0
-rw-rw-r--.  1 hadoop hadoop 177279333  6월  8  2016 pig-0.16.0.tar.gz
lrwxrwxrwx.  1 hadoop hadoop        25  5월 26 19:08 spark -> spark-1.6.2-bin-hadoop2.6
drwxr-xr-x. 12 hadoop hadoop       210  6월 22  2016 spark-1.6.2-bin-hadoop2.6
-rw-rw-r--.  1 hadoop hadoop 278057117  6월 25  2016 spark-1.6.2-bin-hadoop2.6.tgz

~~~

##### Tarball 파일 삭제

4개의 Tarball 파일 삭제
~~~
[12]$ rm  hadoop-2.6.4.tar.gz                  
      rm  pig-0.16.0.tar.gz
      rm  apache-hive-1.2.1-bin.tar.gz  
      rm  spark-1.6.2-bin-hadoop2.6.tgz
~~~

#####확인
~~~
[13]$ ll
~~~
~~~
[hadoop@client ~]$ rm  hadoop-2.6.4.tar.gz
[hadoop@client ~]$ rm  pig-0.16.0.tar.gz
[hadoop@client ~]$ rm  apache-hive-1.2.1-bin.tar.gz
[hadoop@client ~]$ rm  spark-1.6.2-bin-hadoop2.6.tgz
[hadoop@client ~]$ ll
합계 1000
drwxrwxr-x.  8 hadoop hadoop    159  5월 26 19:07 apache-hive-1.2.1-bin
-rw-rw-r--.  1 hadoop hadoop   1512  9월 17  2016 bashrc2.txt
lrwxrwxrwx.  1 hadoop hadoop     25  5월 26 19:07 hadoop -> /home/hadoop/hadoop-2.6.4
drwxr-xr-x.  9 hadoop hadoop    149  2월 12  2016 hadoop-2.6.4
lrwxrwxrwx.  1 hadoop hadoop     21  5월 26 19:07 hive -> apache-hive-1.2.1-bin
-rw-rw-r--.  1 hadoop hadoop 168409  9월 17  2016 hive-1.2.1-site.xml
-rw-rw-r--.  1 hadoop hadoop 843090  3월 24  2013 mysql-connector-java-5.1.23-bin.jar
lrwxrwxrwx.  1 hadoop hadoop     10  5월 26 19:07 pig -> pig-0.16.0
drwxr-xr-x. 16 hadoop hadoop   4096  6월  2  2016 pig-0.16.0
lrwxrwxrwx.  1 hadoop hadoop     25  5월 26 19:08 spark -> spark-1.6.2-bin-hadoop2.6
drwxr-xr-x. 12 hadoop hadoop    210  6월 22  2016 spark-1.6.2-bin-hadoop2.6
~~~


#### 가상 머신 중단 및 VDI 이미지 백업하기


로그아웃 -> 다시 root 계정
~~~
[1]$ exit
~~~
디스크 용량 확인
~~~
[2]$ df
~~~
전원끄기 신호 보내기
~~~
[3]$ shutdown  -h  now
~~~

#### VDI 파일 백업하기

~~~
[hadoop@client ~]$ exit
logout
[root@client ~]# df
Filesystem     1K-blocks    Used Available Use% Mounted on
/dev/sda3        3770368 2867824    902544  77% /
devtmpfs          586868       0    586868   0% /dev
tmpfs             596464       0    596464   0% /dev/shm
tmpfs             596464    7784    588680   2% /run
tmpfs             596464       0    596464   0% /sys/fs/cgroup
/dev/sda1         201380   94904    106476  48% /boot
tmpfs             119296       0    119296   0% /run/user/0

[root@client ~]# shutdown  -h  now
~~~



#### 리눅스 환경 설정
=> 이제부터는 root가 아닌 hadoop 계정으로 작업합니다.

~~~
[1]$ cp  .bashrc  org_bashrc
[2]$ cp  bashrc2.txt  .bashrc
[3]$ source  .bashrc
[4]$ cat  .bashrc
[5]$ env
~~~

* /home/hadoop/.bashrc : hadoop 계정의 환경 설정 파일
* env : 환경 설정 조회 프로그램

~~~
[hadoop@client ~]$ cp  .bashrc  org_bashrc
[hadoop@client ~]$ cp  bashrc2.txt  .bashrc
[hadoop@client ~]$ source  .bashrc
[hadoop@client ~]$ cat .bashrc

# .bashrc

if [ -f /etc/bashrc ]; then
        . /etc/bashrc
fi

#-----------------------------------------------
# HADOOP Config Start

pathmunge () {
    case ":${PATH}:" in
        *:"$1":*)
            ;;
        *)
            if [ "$2" = "after" ] ; then
                PATH=$PATH:$1
            else
                PATH=$1:$PATH
            fi
    esac
}

export JAVA_HOME=/usr/local/java
export CLASSPATH=/usr/local/java/jre/lib/*
pathmunge /usr/local/java before
pathmunge /usr/local/java/bin before

export BASEHOME=/home/hadoop

export HADOOP_PREFIX=$BASEHOME/hadoop
export HADOOP_HOME=$BASEHOME/hadoop
export HADOOP_INSTALL=$HADOOP_HOME
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop

export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native"
export HADOOP_CLASSPATH=$JAVA_HOME/lib/tools.jar

export PIG_HOME=$BASEHOME/pig
export PIG_CLASSPATH=$BASEHOME/hadoop/conf

export HIVE_HOME=$BASEHOME/hive
export HIVE_CONF_DIR=$BASEHOME/hive/conf
export HIVE_CLASS_PATH=$HIVE_CONF_DIR
export HADOOP_USER_CLASSPATH_FIRST=true

export SPARK_HOME=/home/hadoop/spark
export SPARK_CONF_DIR=$SPARK_HOME/conf

#pathmunge $BASEHOME/sqoop/bin
pathmunge $BASEHOME/pig/bin
pathmunge $BASEHOME/hive/bin
pathmunge $BASEHOME/hadoop/bin
~~~
HADOOP Config End

~~~
[hadoop@client ~]$ env
SPARK_HOME=/home/hadoop/spark
HOSTNAME=localhost.localdomain
PIG_HOME=/home/hadoop/pig
SHELL=/bin/bash
TERM=xterm
HIVE_CLASS_PATH=/home/hadoop/hive/conf
HADOOP_HOME=/home/hadoop/hadoop
HISTSIZE=1000
HADOOP_PREFIX=/home/hadoop/hadoop
SPARK_CONF_DIR=/home/hadoop/spark/conf
YARN_HOME=/home/hadoop/hadoop
USER=hadoop
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arj=01;31:*.taz=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lz=01;31:*.xz=01;31:*.bz2=01;31:*.tbz=01;31:*.tbz2=01;31:*.bz=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.rar=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
HADOOP_COMMON_LIB_NATIVE_DIR=/home/hadoop/hadoop/lib/native
MAIL=/var/spool/mail/hadoop
PATH=/home/hadoop/hadoop/bin:/home/hadoop/hive/bin:/home/hadoop/pig/bin:/usr/local/java/bin:/usr/local/java:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hadoop/bin
HADOOP_HDFS_HOME=/home/hadoop/hadoop
HIVE_HOME=/home/hadoop/hive
HADOOP_COMMON_HOME=/home/hadoop/hadoop
PWD=/home/hadoop
JAVA_HOME=/usr/local/java
HADOOP_CLASSPATH=/usr/local/java/lib/tools.jar
HADOOP_INSTALL=/home/hadoop/hadoop
PIG_CLASSPATH=/home/hadoop/hadoop/conf
HADOOP_CONF_DIR=/home/hadoop/hadoop/etc/hadoop
LANG=ko_KR.UTF-8
HADOOP_OPTS=-Djava.library.path=/home/hadoop/hadoop/lib/native
HISTCONTROL=ignoredups
SHLVL=1
HOME=/home/hadoop
HADOOP_MAPRED_HOME=/home/hadoop/hadoop
LOGNAME=hadoop
CLASSPATH=/usr/local/java/jre/lib/*
LESSOPEN=||/usr/bin/lesspipe.sh %s
BASEHOME=/home/hadoop
HADOOP_USER_CLASSPATH_FIRST=true
G_BROKEN_FILENAMES=1
HIVE_CONF_DIR=/home/hadoop/hive/conf
_=/bin/env
~~~
---------------------------------------------------------

- JDK 버전 확인
~~~
[6]$ javac -version
~~~

- 현재 실행되는 자바 프로세스 조회(jps만 나옴)
~~~
[7]$ jps
~~~
=> 현재 머신에서 실행되고 있는 자바 프로그램 조회하기
~~~
[hadoop@client ~]$ javac -version
javac 1.7.0_55

[hadoop@client ~]$ jps
1657 Jps
~~~
[Note] 1657 번호는 리눅스에서 실행되는 프로세스의
       Random ID 값(각자 다른 값을 가짐)
---------------------------------------------------------



#### SSH 설정 : .ssh 디렉터리 생성하기

-> 클러스터의 수십,수백대의 머신에 접속하기 위해서

-> 가상머신을 복제하여 총 3대를 만든 후
   비밀번호 없이 SSH 접속이 가능하도록 설정

[NOTE] 처음 ssh 명령을 실행할 때 비밀번호를 물어보면 그냥 Enter를 3번.
~~~
[8]$ ssh localhost

[9]$ ls -al .ssh

[10]$ rm .ssh/known_hosts  
~~~

~~~
[hadoop@client ~]$ ssh localhost
Warning: Permanently added 'localhost' (RSA) to the list of known hosts.
hadoop@localhost's password:
Permission denied, please try again.
hadoop@localhost's password:
Permission denied, please try again.
hadoop@localhost's password:
Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).
~~~
~~~
[hadoop@client ~]$ ls -al  .ssh
합계 12
drwx------. 2 hadoop hadoop 4096 2017-05-06 16:50 .
drwx------. 3 hadoop hadoop 4096 2017-05-06 16:50 ..
-rw-r--r--. 1 hadoop hadoop  391 2017-05-06 16:50 known_hosts
[hadoop@client ~]$ rm .ssh/known_hosts
~~~
#### (4) 아파치 하둡 설정
------------------------------------------------------------
------------------------------------------------------------

###### 하둡 설정

- 하둡 설정 디렉터리 : /home/hadoop/hadoop/etc/hadoop

=> 다음에 나오는 7개의 파일을 편집하세요.
~~~
[2]$   hadoop-env.sh
       core-site.xml
       hdfs-site.xml
       mapred-site.xml
       yarn-site.xml
       log4j.properties
       slaves
~~~
* 1. 하둡 환경 설정 파일 : hadoop-env.sh
~~~
export JAVA_HOME=/usr/local/java

export HADOOP_PREFIX=${HADOOP_HOME}

export HADOOP_COMMON_LIB_NATIVE_DIR=${HADOOP_PREFIX}/lib/native

export HADOOP_OPTS="${HADOOP_OPTS} -XX:-PrintWarnings -Djava.library.path=${HADOOP_PREFIX}/lib/native"
~~~

* 2. 하둡 코어 설정 : core-site.xml

- 네임노드 -> hdfs://namenode:8020/
~~~
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
 <property>
  <name>fs.defaultFS</name>
   <value>hdfs://namenode.hadoop.kr:8020/</value>
 </property>
 <property>
  <name>io.file.buffer.size</name>
   <value>131072</value>
 </property>
</configuration>
~~~

* 3. HDFS 설정 : hdfs-site.xml

- 복제인수는 1->3으로 변경해야 함
- HDFS 네임노드 웹UI 호스트명/포트           ->    namenode:50070
- HDFS 보조네임노드 웹UI 호스트명/포트       ->  secondnode:50090
- HDFS 데이터노드 웹UI 호스트명/포트         ->    datanode:50010 * 잘 안됨
~~~
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
 <property>
  <name>dfs.replication</name>
  <value>1</value>
 </property>
 <property>
  <name>dfs.namenode.http-address</name>
  <value>namenode.hadoop.kr:50070</value>
 </property>
 <property>
  <name>dfs.namenode.secondary.http-address</name>
  <value>secondnode.hadoop.kr:50090</value>
 </property>
 <property>
  <name>dfs.datanode.http-address</name>
  <value>0.0.0.0:50010</value>
 </property>
 <property>
  <name>dfs.namenode.name.dir</name>
   <value>file:///data/name1,file:///data/name2</value>
 </property>
 <property>
  <name>dfs.datanode.data.dir</name>
   <value>file:///data/data</value>
 </property>
 <property>
  <name>dfs.namenode.checkpoint.dir</name>
   <value>file:///data/namesecondary</value>
 </property>
</configuration>
~~~

* 4. MapReduce 2.0 설정 : mapred-site.xml
~~~
- mapreduce.jobhistory.address(IPC Port)  -> namenode:10020
- MapReduce 히스토리 서버 호스트명/포트   -> namenode:19888

<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
 <property>
  <name>mapreduce.framework.name</name>
   <value>yarn</value>
 </property>
 <property>
  <name>mapreduce.jobhistory.address</name>
   <value>namenode.hadoop.kr:10020</value>
 </property>
 <property>
  <name>mapreduce.jobhistory.webapp.address</name>
   <value>namenode.hadoop.kr:19888</value>
 </property>
</configuration>
~~~
* 5. YARN 설정 : yarn-site.xml

- YARN 리소스매니저 웹UI 호스트명/포트 -> secondnode:8088
- YARN 노드매니저 웹UI 호스트명/포트   -> namenode:8042 secondnode:8042 datanode(1-N):8042
~~~
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
 <property>
  <name>yarn.resourcemanager.hostname</name>
    <value>secondnode.hadoop.kr</value>
 </property>
 <property>
  <name>yarn.nodemanager.local-dirs</name>
    <value>/data/nm</value>
  </property>
 <property>
  <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
 </property>
 <property>
  <name>yarn.nodemanager.resource.cpu-vcores</name>
    <value>2</value>
 </property>
</configuration>
~~~

* 6. 하둡 로그 설정 : log4j.properties

- 로그 수준을 INFO에서 ERROR으로 변경해야 함

~~~
hadoop.root.logger=ERROR,console
~~~

* 7. 워커노드 설정 : slaves
~~~
datanode1.hadoop.kr
datanode2.hadoop.kr
~~~

**설정이 잘 안되면 다음 방법을 사용하세요!**

- 클러스터모드 하둡 설정 파일 다운로드
~~~
[0]$ cd
[1]$ wget http://www.db21.co.kr/hadoop/hdconf_2017.tgz
~~~
- 압축 풀기
~~~
[2]$ tar xvzf hdconf_2017.tgz
~~~
- 내려받은 설정 파일 확인
~~~
[3]$ ll etc_hadoop_2017
~~~
- 설정 파일을 하둡 설정 디렉터리에 덮어쓰기
~~~
[4]$ cp etc_hadoop_2017/*  hadoop/etc/hadoop/

[5]$ echo 'datanode1.hadoop.kr' > hadoop/etc/hadoop/slaves
     echo 'datanode2.hadoop.kr' >> hadoop/etc/hadoop/slaves

[6]$ cat hadoop/etc/hadoop/slaves
~~~

~~~
[hadoop@client ~]$ wget http://www.db21.co.kr/hadoop/hdconf_2017.tgz
--2017-06-01 14:27:00--  http://www.db21.co.kr/hadoop/hdconf_2017.tgz
Resolving www.db21.co.kr (www.db21.co.kr)... 121.124.124.244
Connecting to www.db21.co.kr (www.db21.co.kr)|121.124.124.244|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 4465 (4.4K) [application/x-tar]
Saving to: ‘hdconf_2017.tgz’

100%[======================================>] 4,465       --.-K/s   in 0.006s

2017-06-01 14:27:00 (788 KB/s) - ‘hdconf_2017.tgz’ saved [4465/4465]

[hadoop@client ~]$  tar xvzf hdconf_2017.tgz
etc_hadoop_2017/
etc_hadoop_2017/hadoop-env.sh
etc_hadoop_2017/yarn-site.xml
etc_hadoop_2017/hdfs-site.xml
etc_hadoop_2017/core-site.xml
etc_hadoop_2017/log4j.properties
etc_hadoop_2017/mapred-site.xml

[hadoop@client ~]$ ll etc_hadoop_2017
합계 32
-rw-r--r--. 1 hadoop hadoop   321  5월 25 16:56 core-site.xml
-rw-r--r--. 1 hadoop hadoop  2737  5월 25 16:57 hadoop-env.sh
-rw-r--r--. 1 hadoop hadoop   862  5월 25 16:56 hdfs-site.xml
-rw-r--r--. 1 hadoop hadoop 11292  5월 25 16:57 log4j.properties
-rw-rw-r--. 1 hadoop hadoop   453  6월  1 14:25 mapred-site.xml
-rw-r--r--. 1 hadoop hadoop   545  5월 25 16:56 yarn-site.xml

[hadoop@client ~]$ cp etc_hadoop_2017/*  hadoop/etc/hadoop/

[hadoop@client ~]$ echo 'datanode1.hadoop.kr' > hadoop/etc/hadoop/slaves
[hadoop@client ~]$ echo 'datanode2.hadoop.kr' >> hadoop/etc/hadoop/slaves

[hadoop@client ~]$ cat hadoop/etc/hadoop/slaves                    
datanode1.hadoop.kr
datanode2.hadoop.kr
~~~



# 하둡 기본 명령어
# 샘플 데이터
